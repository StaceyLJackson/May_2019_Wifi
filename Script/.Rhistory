filter(BUILDINGID==2)
#Save WAPs in a vector
WAPs_training<-grep("WAP", names(trainingDataBuilding0), value=T)
# Get the best mtry
bestmtry_rf<-tuneRF(WAPs_training, trainingDataBuilding0$BUILDINGID,trainingDataBuilding0$FLOOR ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
# Get the best mtry
bestmtry_rf<-tuneRF(WAPs_training, trainingDataBuilding0$BUILDINGID,trainingDataBuilding0$FLOOR, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
#Random Forest
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=WAPs_training + BUILDINGID, data = trainingDataBuilding0, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
trainingData5 <- trainingData5 %>% filter(USERID != 6)
trainingData6<-trainingData5[,-c(435:440)]
validationData6<-validationData5[,-c(435:439)]
sample <- trainingData6 %>% group_by(FLOOR, BUILDINGID) %>% sample_n(100)
table(sample$FLOOR)
table(sample$BUILDINGID)
a <- htmltools::tagList()
for(i in unique(sample$BUILDINGID)){
a[[i]] <- sample %>% dplyr:: filter(BUILDINGID == i) %>% plot_ly(type = "scatter3d",
x = ~ LATITUDE,
y = ~ LONGITUDE,
z = ~ FLOOR,
mode = 'markers')
}
a[[1]]
a[[2]]
a[[3]]
#Saving the waps in a vector - training
WAPs_training<-grep("WAP", names(trainingData6), value=T)
bestmtry_rf<-tuneRF(sample[WAPs_training], sample$BUILDINGID, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
bestmtry_rf<-tuneRF(sample[WAPs_training], sample$BUILDINGID, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
rf_reg_caret<-train(y=sample$BUILDINGID, x=sample[WAPs_training], data = sample, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
predicted_building<-predict(rf_reg_caret,validationData6)
postResample(pred =predicted_building,obs=validationData6$BUILDINGID)
confusionMatrix(predicted_building, validationData6$BUILDINGID)
trainingDataBuilding0 <- trainingData6%>%
filter(BUILDINGID==0)
trainingDataBuilding1 <- trainingData6%>%
filter(BUILDINGID==1)
trainingDataBuilding2 <- trainingData6%>%
filter(BUILDINGID==2)
validationDataBuilding0<-validationData6%>%
filter(BUILDING==0)
validationDataBuilding0<-validationData6%>%
filter(BUILDINGID==0)
validationDataBuilding1<-validationData6%>%
filter(BUILDINGID==1)
validationDataBuilding2<-validationData6%>%
filter(BUILDINGID==2)
#Save WAPs in a vector
WAPs_training<-grep("WAP", names(trainingDataBuilding0), value=T)
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=WAPs_training + BUILDINGID, data = trainingDataBuilding0, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
fitControl<-trainControl(method="repeatedcv",number = 5,repeats=1)
KNNfit1<-train(FLOOR~.,data=trainingDataBuilding0,method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
#KNN
fitControl<-trainControl(method="repeatedcv",number = 5,repeats=1)
KNNfit1<-train(FLOOR~.,data=trainingDataBuilding0,method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
KNNfit1<-train(FLOOR~WAPs_training+BUILDINGID,data=trainingDataBuilding0,method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
bestmtry_rf<-tuneRF(trainingDataBuilding0[WAPs_training], trainingDataBuilding0$BUILDINGID,trainingDataBuilding0$FLOOR, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=trainingData0[WAPs_training] + BUILDINGID, data = trainingDataBuilding0, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
#RANDOM FOREST
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0[WAPs_training] + BUILDINGID, data = trainingDataBuilding0, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
#RANDOM FOREST
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0[WAPs_training] + trainingDataBuilding0$BUILDINGID, data = trainingDataBuilding0, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
KNNfit1<-train(FLOOR~trainingDataBuilding0[WAPs_training]+BUILDINGID,data=trainingDataBuilding0,method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
trainingDataBuilding0[WAPs_training]
fitControl<-trainControl(method="repeatedcv",number = 5,repeats=1)
KNNfit1<-train(FLOOR~trainingDataBuilding0[WAPs_training]+trainingDataBuilding0$BUILDINGID,data=trainingDataBuilding0,method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
View(validationData6)
View(validationData6)
rf_reg_caret<-train(y=sample$BUILDINGID, x=sample[WAPs_training], data = sample, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=20))
predicted_building<-predict(rf_reg_caret,validationData6)
postResample(pred =predicted_building,obs=validationData6$BUILDINGID)
confusionMatrix(predicted_building, validationData6$BUILDINGID)
#Save WAPs in a vector
WAPs_training<-grep("WAP", names(trainingDataBuilding0), value=T)
# Get the best mtry
bestmtry_rf<-tuneRF(trainingDataBuilding0[WAPs_training], trainingDataBuilding0$BUILDINGID,trainingDataBuilding0$FLOOR, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
# Get the best mtry
bestmtry_rf<-tuneRF(trainingDataBuilding0$BUILDINGID,trainingDataBuilding0$FLOOR, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
bestmtry_rf<-tuneRF(trainingDataBuilding0$BUILDINGID,trainingDataBuilding0$FLOOR, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
bestmtry_rf<-tuneRF(y=trainingDataBuilding0[WAPs_training], (x=trainingDataBuilding0$BUILDINGID + trainingDataBuilding0$FLOOR), ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
# Get the best mtry
bestmtry_rf<-tuneRF(y=trainingDataBuilding0[WAPs_training], (x=trainingDataBuilding0$BUILDINGID, trainingDataBuilding0$FLOOR), ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
# Get the best mtry
bestmtry_rf<-tuneRF(y=trainingDataBuilding0[WAPs_training], x=(trainingDataBuilding0$BUILDINGID + trainingDataBuilding0$FLOOR), ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
bestmtry_rf
bestmtry_rf<-tuneRF(y=trainingDataBuilding0$FLOOR, x=(trainingDataBuilding0$BUILDINGID + trainingDataBuilding0[WAPs_training]), ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
# Get the best mtry
bestmtry_rf<-tuneRF(y=trainingDataBuilding0$FLOOR, x=(trainingDataBuilding0$BUILDINGID, trainingDataBuilding0[WAPs_training]), ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
# Load package
library(randomForest)
#Saving the waps in a vector - training
WAPs_training<-grep("WAP", names(trainingData6), value=T)
# Get the best mtry
bestmtry_rf<-tuneRF(sample[WAPs_training], sample$BUILDINGID, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
#Train a random forest using that mtry
rfFit1<-randomForest(y=sample$BUILDINGID,x=sample[WAPs_training],importance=T,method="rf", ntree=100, mtry=20)
rfFit1
predicted_building<-predict(rfFit1,validationData6)
postResample(pred =predicted_building,obs=validationData6$BUILDINGID)
confusionMatrix(predicted_building, validationData6$BUILDINGID)
# Train a random forest using caret package
rf_reg_caret<-train(y=sample$BUILDINGID, x=sample[WAPs_training], data = sample, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=20))
predicted_building<-predict(rf_reg_caret,validationData6)
postResample(pred =predicted_building,obs=validationData6$BUILDINGID)
confusionMatrix(predicted_building, validationData6$BUILDINGID)
table(sample$FLOOR)
#KNN
fitControl<-trainControl(method="repeatedcv",number = 5,repeats=1)
KNNfit1<-train(FLOOR~trainingDataBuilding0[WAPs_training]+trainingDataBuilding0$BUILDINGID,data=trainingDataBuilding0,method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
View(trainingDataBuilding0)
View(trainingDataBuilding0)
class(predicted_building)
validationData6$predicted_building
validationData7$predicted_building<-as.data.frame(predicted_building)
validationData6$predicted_building<-as.data.frame(predicted_building)
validationData6$predicted_building
names(validationData6)[names(validationData6)=="BUILDINGID"] <- "original_building"
validationData6$predicted_building<-as.data.frame(predicted_building)
names(validationData6)[names(validationData6)=="predicted_building"] <- "BUILDINGID"
# Get the best mtry
bestmtry_rf<-tuneRF(trainingData6[WAPs_training], trainingData6$BUILDINGID, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
names(validationData6)[names(validationData6)=="BUILDINGID"] <- "original_building"
validationData6$predicted_building<-as.data.frame(predicted_building)
names(validationData6)[names(validationData6)=="predicted_building"] <- "BUILDINGID"
#Training
trainingDataBuilding0 <- trainingData6%>%
filter(BUILDINGID==0)
trainingDataBuilding1 <- trainingData6%>%
filter(BUILDINGID==1)
trainingDataBuilding2 <- trainingData6%>%
filter(BUILDINGID==2)
#Validation
validationDataBuilding0<-validationData6%>%
filter(BUILDINGID==0)
if(require("pacman")=="FALSE"){
install.packages('pacman')
library('pacman')
pacman::p_load(here, readxl, plyr, caret, dplyr, doParallel,
lubridate, corrplot, ggplot2,
tidyverse, arules, arulesViz, rstudioapi,RMySQL,
plotly, padr, lubridate, forecast,zoo, htmltools, readr)
} else {
library('pacman')
pacman::p_load(here, readxl, plyr, caret, dplyr, doParallel,
lubridate, corrplot, ggplot2,
tidyverse, arules, arulesViz, rstudioapi,RMySQL,
plotly, padr, lubridate, forecast,zoo,htmltools, readr)
}
#Upload the files
trainingData<-read.csv(file="/Users/staceyjackson/Dropbox (Personal)/Ubiqum/May_2019_Wifi/Dataset/UJIndoorLoc/trainingData.csv", header=TRUE, sep=",")
validationData<-read.csv(file="/Users/staceyjackson/Dropbox (Personal)/Ubiqum/May_2019_Wifi/Dataset/UJIndoorLoc/validationData.csv", header=TRUE, sep=",")
#Look at the classes
str(trainingData)
sapply(trainingData, class)
#change 523-528 to factors - relative position, USERID, PHONEID, BUILDING ID
columns <- c(523:528)
trainingData[,columns] <- lapply(trainingData[,columns], as.factor)
validationData[,columns]<-lapply(validationData[,columns],as.factor)
sapply(trainingData,class)
#change time to POSixt
trainingData$TIMESTAMP <- as.POSIXct(trainingData$TIMESTAMP,origin="1970-01-01")
validationData$TIMESTAMP <- as.POSIXct(validationData$TIMESTAMP,origin="1970-01-01")
#TRAINING DATA
#means<-apply(trainingData[1:520], 2, mean)
#means<-as.data.frame(means)
mean<-0
for (i in 1:520){
mean[i]<-mean(trainingData[,i])
}
mean[521:529]<-0
mean<-as.data.frame(mean)
#delete all the WAPs with a mean of =100
indices<-c()
indices[521:529]<-0
for (i in 1:520){
if (mean[i,]==100){
indices[i]<- i
}
}
trainingData2<- trainingData[is.na(indices)]
trainingData2<-cbind(trainingData2,trainingData[,c(521:529)])
validationData2<-validationData[is.na(indices)]
validationData2<-cbind(validationData2,validationData[,c(521:529)])
phones <- split(trainingData2, trainingData2$PHONEID)
sapply(phones, function(x) {
colMeans(x[, c(1:50)])
})
#variance of the phones
sapply(phones, var)
variance <- sapply(trainingData2[,c(1:465)], var)
not_low_variance_WAP <- sapply(variance, function(x){
(x>5)
})
not_low_variance_WAP<- which(not_low_variance_WAP, arr.ind = TRUE)
not_low_variance_WAP<- as.data.frame(not_low_variance_WAP)
indices2<-not_low_variance_WAP[,1]
trainingData3<- trainingData2[(indices2)]
trainingData4<-cbind(trainingData3,trainingData2[,c(466:474)])
validationData3 <- validationData2[(indices2)]
validationData4<-cbind(validationData3,validationData[,c(521:529)])
#TRAINING DATA
change_WAP_value <- apply(trainingData4[,c(1:430)], 2, function(x) {ifelse(x == 100, -105, x)})
change_WAP_value<-as.data.frame(change_WAP_value)
trainingData5<-cbind(change_WAP_value,trainingData2[,c(466:474)])
#VALIDATION DATA
change_WAP_value <- apply(validationData4[,c(1:430)], 2, function(x) {ifelse(x == 100, -105, x)})
change_WAP_value<-as.data.frame(change_WAP_value)
validationData5<-cbind(change_WAP_value,validationData4[,c(431:439)])
#found WAPs with high values but what to do with them?
trainingData5$high_value <- apply(trainingData5[,c(1:430)], 1, max)
#by user
high_value_user <- select(trainingData5,USERID,high_value)%>%
filter(high_value>-30)
high_value_user
#by phone
high_value_phone <- select(trainingData5,PHONEID,high_value)%>%
filter(high_value>-30)
high_value_phone
#plots
high_value_phone<-as.data.frame(high_value_phone)
p <- ggplot(data=high_value_phone, mapping=aes(x=PHONEID, y=high_value))
p + geom_point()
high_value_user<-as.data.frame(high_value_user)
p <- ggplot(data=high_value_user, mapping=aes(x=USERID, y=high_value))
p + geom_point()
high_value_user1<- trainingData5%>%
select(USERID, high_value)%>%
filter(USERID==1)
p <- ggplot(data=high_value_user1, mapping=aes(x=high_value))
p + geom_histogram()
high_value_user3<- trainingData5%>%
select(USERID, high_value)%>%
filter(USERID==3)
p <- ggplot(data=high_value_user3, mapping=aes(x=high_value))
p + geom_histogram()
high_value_user6<- trainingData5%>%
select(USERID, high_value)%>%
filter(USERID==6)
p <- ggplot(data=high_value_user6, mapping=aes(x=high_value))
p + geom_histogram()
phone19<-trainingData5%>%
select(PHONEID,high_value)%>%
filter(PHONEID==19)
p <- ggplot(data=phone19, mapping=aes(x=high_value))
p + geom_histogram()
high_value_user10<- trainingData5%>%
select(USERID, high_value)%>%
filter(USERID==10)
p <- ggplot(data=high_value_user10, mapping=aes(x=high_value))
p + geom_histogram()
high_value_user14<- trainingData5%>%
select(USERID, high_value)%>%
filter(USERID==14)
p <- ggplot(data=high_value_user14, mapping=aes(x=high_value))
p + geom_histogram()
high_value_user15<- trainingData5%>%
select(USERID, high_value)%>%
filter(USERID==15)
p <- ggplot(data=high_value_user15, mapping=aes(x=high_value))
p + geom_histogram()
high_value_user16<- trainingData5%>%
select(USERID, high_value)%>%
filter(USERID==16)
p <- ggplot(data=high_value_user16, mapping=aes(x=high_value))
p + geom_histogram()
trainingData5 <- trainingData5 %>% filter(USERID != 6)
trainingData6<-trainingData5[,-c(435:440)]
validationData6<-validationData5[,-c(435:439)]
sample <- trainingData6 %>% group_by(FLOOR, BUILDINGID) %>% sample_n(100)
table(sample$FLOOR)
table(sample$BUILDINGID)
a <- htmltools::tagList()
for(i in unique(sample$BUILDINGID)){
a[[i]] <- sample %>% dplyr:: filter(BUILDINGID == i) %>% plot_ly(type = "scatter3d",
x = ~ LATITUDE,
y = ~ LONGITUDE,
z = ~ FLOOR,
mode = 'markers')
}
a[[1]]
a[[2]]
a[[3]]
# Load package
library(randomForest)
#Saving the waps in a vector - training
WAPs_training<-grep("WAP", names(trainingData6), value=T)
# Get the best mtry
bestmtry_rf<-tuneRF(sample[WAPs_training], sample$BUILDINGID, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
#Train a random forest using that mtry
rfFit1<-randomForest(y=sample$BUILDINGID,x=sample[WAPs_training],importance=T,method="rf", ntree=100, mtry=20)
rfFit1
predicted_building<-predict(rfFit1,validationData6)
postResample(pred =predicted_building,obs=validationData6$BUILDINGID)
confusionMatrix(predicted_building, validationData6$BUILDINGID)
# Train a random forest using caret package
rf_reg_caret<-train(y=sample$BUILDINGID, x=sample[WAPs_training], data = sample, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=20))
predicted_building<-predict(rf_reg_caret,validationData6)
postResample(pred =predicted_building,obs=validationData6$BUILDINGID)
confusionMatrix(predicted_building, validationData6$BUILDINGID)
names(validationData6)[names(validationData6)=="BUILDINGID"] <- "original_building"
validationData6$predicted_building<-as.data.frame(predicted_building)
names(validationData6)[names(validationData6)=="predicted_building"] <- "BUILDINGID"
#Training
trainingDataBuilding0 <- trainingData6%>%
filter(BUILDINGID==0)
trainingDataBuilding1 <- trainingData6%>%
filter(BUILDINGID==1)
trainingDataBuilding2 <- trainingData6%>%
filter(BUILDINGID==2)
#Validation
validationDataBuilding0<-validationData6%>%
filter(BUILDINGID==0)
validationDataBuilding1<-validationData6%>%
filter(BUILDINGID==1)
validationDataBuilding2<-validationData6%>%
filter(BUILDINGID==2)
#Save WAPs in a vector
WAPs_training<-grep("WAP", names(trainingDataBuilding0), value=T)
bestmtry_rf<-tuneRF(trainingDataBuilding0[WAPs_training], trainingDataBuilding0$BUILDINGID,trainingDataBuilding0$FLOOR, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
#RANDOM FOREST
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0[WAPs_training] + trainingDataBuilding0$BUILDINGID, data = trainingDataBuilding0, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
# Get the best mtry
bestmtry_rf<-tuneRF(trainingDataBuilding0$BUILDINGID,trainingDataBuilding0$FLOOR, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
bestmtry_rf<-tuneRF(trainingDataBuilding0[WAPs_training],trainingDataBuilding0$FLOOR, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
# Get the best mtry
bestmtry_rf<-tuneRF(y=trainingDataBuilding0$FLOOR, x=(trainingDataBuilding0[WAPs_training] + trainingDataBuilding0$BUILDINGID), ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
# Get the best mtry
bestmtry_rf<-tuneRF(y=trainingDataBuilding0$FLOOR, x= trainingDataBuilding0$BUILDINGID, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
bestmtry_rf<-tuneRF(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0[WAPs_training], ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
trainingDataBuilding0$FLOOR
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0[WAPs_training] + trainingDataBuilding0$BUILDINGID, data = trainingDataBuilding0, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0[WAPs_training], trainingDataBuilding0$BUILDINGID, data = trainingDataBuilding0, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
#RANDOM FOREST
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=c(trainingDataBuilding0[WAPs_training], trainingDataBuilding0$BUILDINGID), data = trainingDataBuilding0, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
WAPs_training
WAPs_training<-grep("WAP", names(trainingDataBuilding0), value=T)
WAPs_training[431] <- "BUILDINGID"
WAPs_training
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0[WAPs_training], data = trainingDataBuilding0, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
#RANDOM FOREST
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0$BUILDINGID, data = trainingDataBuilding0, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
trainingDataBuilding0$BUILDINGID
#Save WAPs in a vector
WAPs_training<-grep("WAP", names(trainingDataBuilding0), value=T)
# Get the best mtry
bestmtry_rf<-tuneRF(y=trainingDataBuilding0$FLOOR, x=(trainingDataBuilding0[WAPs_training] + trainingDataBuilding0$BUILDINGID), ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
# Get the best mtry
bestmtry_rf<-tuneRF(y=trainingDataBuilding0$FLOOR, x=(trainingDataBuilding0[WAPs_training], ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
# Get the best mtry
bestmtry_rf<-tuneRF(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0[WAPs_training], ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
bestmtry_rf<-tuneRF(trainingDataBuilding0$FLOOR,trainingDataBuilding0[WAPs_training], ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
#RANDOM FOREST
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0[WAPs_training], data = trainingDataBuilding0, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
#RANDOM FOREST
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0[WAPs_training], method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
fitControl<-trainControl(method="repeatedcv",number = 5,repeats=1)
KNNfit1<-train(FLOOR~trainingDataBuilding0[WAPs_training],method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
fitControl<-trainControl(method="repeatedcv",number = 5,repeats=1)
KNNfit1<-train(trainingDataBuilding0$FLOOR~trainingDataBuilding0[WAPs_training],method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
class(trainingDataBuilding0$FLOOR)
trainingDataBuilding0$FLOOR
trainingDataBuilding0[FLOOR==4]
trainingDataBuilding0[FLOOR=4]
trainingDataBuilding0[FLOOR==2]
trainingDataBuilding0[,FLOOR==2]
trainingDataBuilding0[,FLOOR=2]
trainingData0%>%filter(FLOOR==4)
trainingDataBuilding0%>%filter(FLOOR==4)
trainingDataBuilding0%>%filter(FLOOR==2)
trainingDataBuilding0 <- trainingData6%>%
filter(BUILDINGID==0 && FLOOR!=4)
trainingDataBuilding0%>%group_by(FLOOR)
trainingDataBuilding0%
trainingDataBuilding0
trainingDataBuilding0 <- trainingData6%>%
filter(BUILDINGID==0 & FLOOR!=4)
trainingDataBuilding0
trainingDataBuilding0%>%group_by(FLOOR)
#Save WAPs in a vector
WAPs_training<-grep("WAP", names(trainingDataBuilding0), value=T)
bestmtry_rf<-tuneRF(trainingDataBuilding0$FLOOR,trainingDataBuilding0[WAPs_training], ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
trainingDataBuilding0$FLOOR
trainingDataBuilding0%>%group_by(FLOOR)
trainingDataBuilding0$FLOOR
bestmtry_rf<-tuneRF(trainingDataBuilding2$FLOOR,trainingDataBuilding2[WAPs_training], ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
bestmtry_rf<-tuneRF(FLOOR,trainingDataBuilding0[WAPs_training], data=trainingDataBuilding0, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
WAPs_training<-grep("WAP", names(trainingDataBuilding0), value=T)
# Get the best mtry
bestmtry_rf<-tuneRF(trainingDataBuilding0[WAPs_training], trainingDataBuilding0$FLOOR, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
bestmtry_rf<-tuneRF(sample[WAPs_training], trainingDataBuilding0$FLOOR, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
bestmtry_rf<-tuneRF(sample[WAPs_training], sample$BUILDINGID, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
rfFit1<-randomForest(y=sample$BUILDINGID,x=sample[WAPs_training],importance=T,method="rf", ntree=100, mtry=10)
rfFit1
predicted_building<-predict(rfFit1,validationData6)
postResample(pred =predicted_building,obs=validationData6$BUILDINGID)
colnames(validationData6)
confusionMatrix(predicted_building, validationData6$BUILDINGID)
rf_reg_caret<-train(y=sample$BUILDINGID, x=sample[WAPs_training], data = sample, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=20))
predicted_building<-predict(rf_reg_caret,validationData6)
postResample(pred =predicted_building,obs=validationData6$BUILDINGID)
#TRAINING DATA
#means<-apply(trainingData[1:520], 2, mean)
#means<-as.data.frame(means)
mean<-0
for (i in 1:520){
mean[i]<-mean(trainingData[,i])
}
mean[521:529]<-0
mean<-as.data.frame(mean)
#delete all the WAPs with a mean of =100
indices<-c()
indices[521:529]<-0
for (i in 1:520){
if (mean[i,]==100){
indices[i]<- i
}
}
trainingData2<- trainingData[is.na(indices)]
trainingData2<-cbind(trainingData2,trainingData[,c(521:529)])
validationData2<-validationData[is.na(indices)]
validationData2<-cbind(validationData2,validationData[,c(521:529)])
variance <- sapply(trainingData2[,c(1:465)], var)
not_low_variance_WAP <- sapply(variance, function(x){
(x>5)
})
not_low_variance_WAP<- which(not_low_variance_WAP, arr.ind = TRUE)
not_low_variance_WAP<- as.data.frame(not_low_variance_WAP)
indices2<-not_low_variance_WAP[,1]
trainingData3<- trainingData2[(indices2)]
trainingData4<-cbind(trainingData3,trainingData2[,c(466:474)])
validationData3 <- validationData2[(indices2)]
validationData4<-cbind(validationData3,validationData[,c(521:529)])
#TRAINING DATA
change_WAP_value <- apply(trainingData4[,c(1:430)], 2, function(x) {ifelse(x == 100, -105, x)})
change_WAP_value<-as.data.frame(change_WAP_value)
trainingData5<-cbind(change_WAP_value,trainingData2[,c(466:474)])
#VALIDATION DATA
change_WAP_value <- apply(validationData4[,c(1:430)], 2, function(x) {ifelse(x == 100, -105, x)})
change_WAP_value<-as.data.frame(change_WAP_value)
validationData5<-cbind(change_WAP_value,validationData4[,c(431:439)])
trainingData5 <- trainingData5 %>% filter(USERID != 6)
trainingData6<-trainingData5[,-c(435:440)]
validationData6<-validationData5[,-c(435:439)]
sample <- trainingData6 %>% group_by(FLOOR, BUILDINGID) %>% sample_n(100)
table(sample$FLOOR)
table(sample$BUILDINGID)
a <- htmltools::tagList()
for(i in unique(sample$BUILDINGID)){
a[[i]] <- sample %>% dplyr:: filter(BUILDINGID == i) %>% plot_ly(type = "scatter3d",
x = ~ LATITUDE,
y = ~ LONGITUDE,
z = ~ FLOOR,
mode = 'markers')
}
a[[1]]
a[[2]]
a[[3]]
# Load package
library(randomForest)
#Saving the waps in a vector - training
WAPs_training<-grep("WAP", names(trainingData6), value=T)
bestmtry_rf<-tuneRF(sample[WAPs_training], sample$BUILDINGID, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
rfFit1<-randomForest(y=sample$BUILDINGID,x=sample[WAPs_training],importance=T,method="rf", ntree=100, mtry=10)
rfFit1
predicted_building<-predict(rfFit1,validationData6)
postResample(pred =predicted_building,obs=validationData6$BUILDINGID)
confusionMatrix(predicted_building, validationData6$BUILDINGID)
rf_reg_caret<-train(y=sample$BUILDINGID, x=sample[WAPs_training], data = sample, method="rf", ntree=100,tuneGrid=expand.grid(.mtry=20))
predicted_building<-predict(rf_reg_caret,validationData6)
postResample(pred =predicted_building,obs=validationData6$BUILDINGID)
confusionMatrix(predicted_building, validationData6$BUILDINGID)
names(validationData6)[names(validationData6)=="BUILDINGID"] <- "original_building"
validationData6$predicted_building<-as.data.frame(predicted_building)
names(validationData6)[names(validationData6)=="predicted_building"] <- "BUILDINGID"
#Training
trainingDataBuilding0 <- trainingData6%>%
filter(BUILDINGID==0 & FLOOR!=4)
trainingDataBuilding1 <- trainingData6%>%
filter(BUILDINGID==1)
trainingDataBuilding2 <- trainingData6%>%
filter(BUILDINGID==2)
#Validation
validationDataBuilding0<-validationData6%>%
filter(BUILDINGID==0)
validationDataBuilding1<-validationData6%>%
filter(BUILDINGID==1)
validationDataBuilding2<-validationData6%>%
filter(BUILDINGID==2)
#Save WAPs in a vector
WAPs_training<-grep("WAP", names(trainingDataBuilding0), value=T)
bestmtry_rf<-tuneRF(trainingDataBuilding0[WAPs_training], trainingDataBuilding0$FLOOR, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
trainingDataBuilding0[WAPs_training]
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0[WAPs_training], method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
bestmtry_rf<-tuneRF(trainingDataBuilding0[WAPs_training], trainingDataBuilding0$FLOOR, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, plot=T)
rf_reg_caret<-train(y=trainingDataBuilding0$FLOOR, x=trainingDataBuilding0[WAPs_training], method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
rf_reg_caret<-train(y=trainingDataBuilding2$FLOOR, x=trainingDataBuilding2[WAPs_training], method="rf", ntree=100,tuneGrid=expand.grid(.mtry=10))
View(rf_reg_caret)
View(rf_reg_caret)
predicted_floor<-predict(rf_reg_caret,validationDataBuilding2)
postResample(pred =predicted_floor,obs=validationDataBuilding2$FLOOR)
confusionMatrix(predicted_floor, validationDataBuilding2$FLOOR)
fitControl<-trainControl(method="repeatedcv",number = 5,repeats=1)
KNNfit1<-train(trainingDataBuilding2$FLOOR~trainingDataBuilding2[WAPs_training],method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
trainingDataBuilding2[WAPs_training]
fitControl<-trainControl(method="repeatedcv",number = 5,repeats=1)
KNNfit1<-train(trainingDataBuilding2$FLOOR~unlist(trainingDataBuilding2[WAPs_training]),method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
KNNfit1<-train(FLOOR~WAPs_training,data=trainingDataBuilding0, method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
KNNfit1<-train(FLOOR~.,data=trainingDataBuilding0, method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
KNNfit1<-train(FLOOR~.,data=trainingDataBuilding2, method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
colnames(trainingDataBuilding2)
KNNfit1<-train(FLOOR~.-BUILDINGID-LATITUDE-LONGITUDE,data=trainingDataBuilding2, method="knn",trControl=fitControl,preProcess = c("center","scale"), tuneLength=20)
